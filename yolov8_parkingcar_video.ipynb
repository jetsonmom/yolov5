{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNN/nM7Tx34lHQgLXPDwfRb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jetsonmom/yolov5/blob/main/yolov8_parkingcar_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McQe5-3yYJKT"
      },
      "outputs": [],
      "source": [
        "# 내 구글 드라이브에 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지와 모듈을 불러옴\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "2hoeysMMZndv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detection 하기 전에 원본 동영상을 Display\n",
        "# video = io.open('gdrive/My Drive/CV/Parking Car Count/video/parking.mp4', 'r+b').read()\n",
        "video = io.open('/content/gdrive/My Drive/CV/video/Parking Car Count/parking.mp4', 'r+b').read()\n",
        "encoded = base64.b64encode(video)\n",
        "HTML(data='''<video width=\"30%\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
        "             </video>'''.format(encoded.decode('ascii')))"
      ],
      "metadata": {
        "id": "Zbze4QLeZs1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/gdrive/My Drive/CV/video/Parking Car Count/parking.mp4'  # Detection 할 원본 동영상\n",
        "min_confidence = 0.5   # detection 으로 인정할 최소 확률(신뢰도) 지정\n",
        "output_name = 'parking_car_count_video.mp4'  # Detection 된 output 동영상\n",
        "elapsed_time = 0       # 총 경과시간 초기화"
      ],
      "metadata": {
        "id": "xq9EnpzuZt3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detectAndDisplay(frame):\n",
        "    start_time = time.time()\n",
        "    img = cv2.resize(frame, None, fx=0.9, fy=0.9)\n",
        "    height, width, channels = img.shape\n",
        "\n",
        "    # YOLOv3의 Detecting model 3가지(320×320, 416×416, 608×608)\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Showing informations on the screen\n",
        "    confidences = []    # detection 한 Class 의 신뢰도(확률)를 저장하는 배열 정의\n",
        "    boxes = []          # detection 한 boxing 정보를 저장하는 배열 정의\n",
        "\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)      # detection 한 Class id\n",
        "            confidence = scores[class_id]     # detection 한 Class 의 신뢰도(확률)\n",
        "            # Filter only 'car'\n",
        "            if class_id == 2 and confidence > min_confidence:\n",
        "                # Object detected\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Rectangle coordinates\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])             # boxing 정보를 boxes 배열에 저장\n",
        "                confidences.append(float(confidence))  # 신뢰도(확률)을 confidences 배열에 저장\n",
        "\n",
        "    # apply non-max suppression\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, min_confidence, 0.4)    # 박스안에 박스(노이즈)를 하나로 만들어 준다.\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:    # 노이즈가 제거된 박스만 표시해 준다.\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = '{:,.2%}'.format(confidences[i])  # 신뢰도(확률)\n",
        "            print(i, label)\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
        "            cv2.rectangle(img, (x, y - 20), (x + w, y), (0, 255, 0), -1)\n",
        "            cv2.putText(img, label, (x + 5, y - 5), cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 1)\n",
        "\n",
        "    text = \"number of parked cars : {} \".format(len(indexes))\n",
        "    cv2.putText(img, text, (40, 40), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 10)\n",
        "    cv2.putText(img, text, (40, 40), cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
        "\n",
        "    process_time = time.time() - start_time\n",
        "    global elapsed_time\n",
        "    elapsed_time += process_time   # 총 경과시간 누적\n",
        "    print(\"=== A frame took {:.3f} seconds\".format(process_time))\n",
        "\n",
        "    # video 를 disk 에 output 하기 위해 writer 를 초기화한다.\n",
        "    global writer\n",
        "    if writer is None and output_name is not None:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(output_name, fourcc, 30,\n",
        "                (img.shape[1], img.shape[0]), True)\n",
        "\n",
        "    # disk 에 frame 을 write 합니다.\n",
        "    if writer is not None:\n",
        "        writer.write(img)"
      ],
      "metadata": {
        "id": "k2KiONu9ZxCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Yolo\n",
        "net = cv2.dnn.readNet(\"gdrive/My Drive/CV/Object Detection_YOLO/yolov3.weights\", \"gdrive/My Drive/CV/Object Detection_YOLO/yolov3.cfg\")\n",
        "classes = []  # detection 할 Object(Class) list 배열을 정의\n",
        "with open(\"gdrive/My Drive/CV/Object Detection_YOLO/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]   # 80개의 Object(class)를 구분할 수 있는 Object의 이름을 classes 배열에 넣어준다.\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# 원본 동영상에서 video stream을 읽어온다.\n",
        "cap = cv2.VideoCapture(file_name)\n",
        "writer = None\n",
        "if not cap.isOpened:\n",
        "    print('--(!)Error opening video capture')\n",
        "    exit(0)\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if frame is None:\n",
        "        # close the video file pointers\n",
        "        cap.release()\n",
        "        # close the writer point\n",
        "        writer.release()\n",
        "        print('--(!) No captured frame -- Break!')\n",
        "        print(\"elapsed time {:.3f} seconds\".format(elapsed_time))\n",
        "        break\n",
        "    detectAndDisplay(frame)"
      ],
      "metadata": {
        "id": "BUq4wfZjZ7UX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}